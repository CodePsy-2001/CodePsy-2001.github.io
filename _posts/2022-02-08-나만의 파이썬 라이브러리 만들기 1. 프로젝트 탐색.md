---
title: "나만의 파이썬 라이브러리 만들기 1. 프로젝트 탐색"
date: 2022-02-08 04:43:33 +0900
categories: [프로그래밍, 기술비평]
tags: [python]
---

# 서론

나는 예전부터 나만의 파이썬 라이브러리를 만들어보고 싶었다.

하지만, 이미 개발해놓은 코드가 한무더기인 오픈소스 세상에서, 오직 '나만'의 코드를 만들기는 너무나도 어려웠다. 남이 이미 해둔 작업에 PR을 보내기보단, 바닥부터 온전히 내 것이라고 할 수 있는 코드를 만들어보고 싶었는데!

고민이 깊어지던 와중... **쒸프트끼가 안빠찌는 라이브러리**라는 간단한 아이디어를 떠올려냈다.

한국어 문자열을 집어넣으면, 쉬프트키를 누른 상태로 입력한 문자열을 반환해주는 것이다.

```python
assert hanshift.shift('학교 앞 중국집 짜장면은 4500원입니다.') == '핚꾜 앞 쭝꾺찌ㅃ 짜짱면은 4500원이ㅃ니따.'
assert hanshift.unshift('짜장면을 맛있게 먹었습니다.') == '자장면을 맛잇게 먹엇습니다.'
```

테스트 주도 개발을 한다면 대강 이런 모양이렸다.

한글의 자모를 분리하고, 다시 합치는 작업만 거친다면 쉽게 구현 가능한 아이디어로 보였다.

# 본론

## hangul-toolkit

한글 자모 분리에 [hangul-toolkit](https://github.com/bluedisk/hangul-toolkit)이라는 라이브러리가 주로 쓰인다는 것을 알게 되었다.

(머신러닝 embedding시 한글 완성형 글자를 이용하면 벡터 수가 너무 많아지는지라 자모별로 쪼개기도 한다고...)

처음에는 이 라이브러리를 사용해 shift, unshift 작업만 간단히 구현하고 프로젝트를 마무리지을 심산으로 리포지토리를 포크해왔으나, 내부 코드를 자세히 살펴보는 과정에서 hangul-toolkit 라이브러리의 문제점을 알게 되었다.

### 파악한 문제점들

- for문에 지역변수를 사용했지만, 한 줄 제너레이터로 훨씬 쉽게 표현할 수 있는 부분이 많이 보였다.
- letter와 text의 구분, 한자/영숫자 검출 기준 등의 유니코드 표준을 따르지 않고 자의적이었다. 각 언어의 첫 문자와 마지막 문자의 유니코드 값을 하드코딩해두었는데, 한글/한자의 경우 예외사항이 많아서 그런 방식으로 처리하면 안 된다.
  - 유니코드 표준을 따를 경우 block별로 문자를 구분해 쉽게 언어를 검출할 수 있다. [pyunicodeblock](https://github.com/neuront/pyunicodeblock) 같은 관련 라이브러리도 있다.
- compose 구분자로 곰돌이 모양의 아이콘을 사용하고 있었는데, 이미 한글 조합형 인코딩 지원을 위해 유니코드 표준에 hangul filler라는 문자가 따로 할당되어 있다.
  - 표준을 따르도록 고친다면 각종 문자열 깨짐 문제도 해결할 수 있을 것 같다.
  - 초/중/종성이 모두 모여 완성된 글자인지를 검증하는 로직이 추가될 수 있다.
- 초성, 중성, 종성을 chosung, joongsung, jongsung 같은 식으로 이름지어두었다. joongsung과 jungsung을 혼용한 부분도 있어 혼란을 더욱 가중시켰다.
  - onset, nucleus, coda 라는 음운학 용어를 사용하면 된다.

- context 관리자를 제공할 수 있는 가능성이 보였다. 의사코드로 쓴다면 이렇다.

  - ```python
    with (
        hgtk.decompose_context() as decom
        open("korean.txt", "w") as fp
    ):
        fp.write("맛있는 김치")
        # "ㅁㅏㅅㅇㅣㅆㄴㅡㄴ ㄱㅣㅁㅊㅣ" 가 파일에 저장된다.
    ```

  - string 앞뒷단에서 compose나 decompose를 자동으로 거치도록 만든다.

- composer, decomposer를 객체로 분리할 수 있는 가능성이 보였다.

  - 이 경우 block별 언어 구분도 UnicodeBlock, LangDetector 등의 객체로 분리할 수 있겠다.

## 정리

이번 탐색을 통해 알게 된 점을 정리하면 다음과 같았다.

1. 한국어의 음운학적 원리를 구현해둔 파이썬 라이브러리가 별로 없다. 쉬프트키 외에도, 낱자/미완성 음절 등을 구분하거나, 한국어 발음의 표준 로마자 표기를 제공한다든가, 하는 라이브러리가 별로 없었다.  예를 들어,[unihandecode](https://github.com/miurahr/unihandecode) 같은 라이브러리는 아예 중국어, 일본어만 제공한다.

2. 쒸프트키 안빠쪄요의 단순 구현은 당초 생각보다도 훨씬 더 쉬울 것 같다. 날잡고 2시간이면 되겠다.

3. '한국어'를 다루는 라이브러리에 대한 여러 아이디어는, 확실히 한 라이브러리에 모두 담기에는 너무 무거운 것 같다. Korea를 주제로 하는 라이브러리 하나에 모두 담기보다, CJK를 셋트로 다루는 (기능별로 분화된) 여러 라이브러리에 각각 기여하는 편이 더 나을 것 같았다.

# 결론

1. 기존 hgtk에 코드 수정사항을 잘 커밋한다.
   - 어차피 한국인만 쓰던 라이브러리라 변수명이 이상해도 괜찮다. CJK용 통합 라이브러리도 아니니까.
   - 어차피 머신러닝 임베딩용으로만 쓰던 라이브러리라 내부 구조가 조금 지저분해도 괜찮다. 어차피 지금보다 더 잘 다듬을 자신도 없다.
   - 그래도 유니코드 block별 언어 검출 관련 부분은 꼭 커밋해 보자.
   - 인라인 제너레이터 등, 성능이 향상될 수 있는 부분도 꼭 커밋해 보자.

2. 쉬프트키 안빠지는 라이브러리는 날잡고 하루동안 만든다.
   - hgtk에 의존성을 갖는다.
   - context 관리자를 제공한다.

3. 한국어 발음의 로마자 표기와 관련된 라이브러리를 하나 만들면 재밌을 것 같다.
   - 2020년 이후 관리가 끊긴 unihandecode에서 포크해 나온 다음, 각종 오픈소스 커뮤니티에 활발히 홍보해봐야겠다.
