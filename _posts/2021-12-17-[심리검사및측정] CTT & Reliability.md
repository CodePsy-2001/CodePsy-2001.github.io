---
title: "[심리검사] CTT & Reliability 신뢰도"
date: 2021-12-17 01:37:14 +0900
categories: [심리학, 필기]
tags: [심리검사및측정]
---



# CTT & Reliability

### 측정의 세 가지 유형

1. Parallel measures (동형 측정치)
   - 이번 강의에서 주로 다루는 내용 - 동형 측정치에서 신뢰도 얻는 법
2. Tau-equivalent measures (타우-동등 측정치)
3. Congeneric measures (일반공동 측정치)





## Strictly Parallel Measures

- 1. 각 개인이 두 측정에서 <u>동일한 실제점수</u>를 가지고,
  2. 각 개인이 두 측정에서 <u>오류 분산이 동일</u>할 때

  두 측정이 <u>엄밀하게</u> 동형이라고 말한다.

- Xpi = Tpi + Epi = **Ti** + Epi
  Xqi = Tqi + Eqi = **Ti** + Eqi
  **Var(Epi) = Var(Eqi)**

- ex) 연구자가 학생들의 사칙연산 능력을 측정하기 위해, 시험문제 2가지를 만들었다.
  만약 두 시험문제가 엄격하게 동형이라면,
  - 같은 학생에 대해 두 시험문제의 실제점수가 완벽하게 같다.
    (같은 학생에 대해 두 시험문제의 관측점수 차이는, 완벽하게 오류에만 의한 것이다.)



한 학생의 실제점수가 4라고 하자. 시험1에서 3점, 시험2에서 4점을 받았다.

이 경우, 만약 두 시험이 엄격하게 동형이라면...

- 시험1의 오류점수가 -1점이고, 시험2의 오류점수가 0점이다.





## Parallel Measures

- 일반적으로 (엄격하지 않게), 동형인 측정치들은 아래의 조건을 만족하는 것을 의미한다.
  - 각 개인이 두 측정에서 <u>실제점수의 분산</u>이 같다.
  - 각 개인이 두 측정에서 <u>오류점수의 분산</u>이 같다.

- ex) 우울 척도에 대한 두 동형인 form에 대해...

  - 양식 A - 나는 어떤 것에도 흥미가 없다, 나는 지쳤다, etc...

  - 양식 B - 나는 패배자라고 느낀다, 나는 완전히 지쳐서 아무것도 할 수 없다, etc...

  위 예시에서 두 form에 대한 개인의 실제점수는 달라야 한다. 양식 B가 더 난이도가 높기 때문이다.
  만약 측정오차가 없다면, 양식 A의 실제점수가 양식 B의 실제점수보다 높아야 한다.

- 다시 말해, 두 형태의 실제점수가 서로 관계를 가질 수 있다.
  - ex) T2i = T1i - 3
    when Form A: X1i = T1i + E1i / Form B: X2i = T2i + E2i
  - 이 경우, 두 척도에서 실제점수는 다르지만, 실제점수의 분산은 동일하다. (더하기만 했으니까)
  - 이런 경우, 엄밀하게 동형은 아니지만, 일반적으로 동형인 측정치라고 말할 수 있다.



### 동형 측정치의 응용

- 동형인 측정치는 변동성의 크기(측정을 받는 개인별의 차이)가 동일하다.

- 동형인 측정치는 같은 신뢰도를 가진다.

- 두 동형 측정치의 공분산은, 각 측정치의 실제점수의 분산과 같다.

- 두 동형 측정치의 공분산은, 각 측정치의 reliability coefficient 값과 동일하다.
  - 헐!! **설문지를 반으로 쪼개서 공분산을 측정하면 신뢰도를 알 수 있구나!!**
  - 정확하게는, 표본으로부터 모집단의 공분산을 추정해야 한다.





## Reliability Coefficient 정의

- Pearson의 Correlation 상관관계:
  - Corr(X,Y) = Cov(X,Y) / √(Var(X)*Var(Y)) = Σ(X변산 * Y변산) / √(Σ(X변산제곱) * Σ(Y변산제곱))
  - 같은 설문지의 두 form 사이의 상관관계를 측정하면 신뢰도를 알 수 있다.
  - 값이 0.612이면, 관측점수의 61.2%를 실제점수가 구성하고 있다고 설명할 수 있다.

동형 측정치를 바탕으로 검사의 신뢰도를 알 수 있다.

그렇다면 <u>검사 후 재검사</u>나, <u>Alternative forms</u>에 대해서는 어떻게 신뢰도를 알 수 있을까?



### 검사-재검사 신뢰도 (test-retest reliability)

- 검사 점수와 재검사 점수는 (이론적으로) 동형 측정이다.
- 검사-재검사의 신뢰도를 측정해, 시험의 신뢰도를 측정할 수 있다.
- 문제점:
  - 실제로 두번 하기는 어렵다
  - 시간 간격이 너무 짧으면 답을 기억하는 등 추가적인 오류가 생긴다.
    너무 길면 실제 변화가 발생하는 등 더이상 두 측정치가 평행하지 않다.
  - 일반적인 인지능력 등 천천히 변화하는 속성은 검사-재검사 신뢰도를 측정해도 좋다.
    빠르게 변하는 속성인 경우에는 검사-재검사 신뢰도 측정을 하는 게 좋지 않다.



### 동형 검사 신뢰도 (alternative forms reliability)

- 측정 도구를 두 개 만들어서 사용한다.
- 두 form의 점수 간 상관관계를 form에 대한 신뢰도로 사용한다.
  - ex) Watson-Glaser 비판적 사고 검사 (WGCTA)
    똑같은 문장을 학생 버전, 직장인 버전으로 만들어서 사용했다.
- 문제점:
  - 실제로 두개 하기는 어렵다
  - 하나의 form에 대한 경험이 다른 form에 대한 응답에 영향을 미칠 수 있다.
    모든 응답자가 동일한 순서로 양식을 작성한다면, 응답에 systemic bias가 생길 수 있다.
    피험자 중 절반은 A-B, 절반은 B-A 순서로 양식에 응답해야 한다.
  - 동형 측정 form 2개를 실제로 만들기는 정말 어렵다.
    양식이 충분히 parellel하지 않으면 신뢰도 계산의 정확도가 떨어진다.



### 합점수 신뢰도 (Composite Score Reliability) 

- 한 번으로 끝낼 수는 없을까?
  - 검사 자체가 parellel한 여러 구성요소 (항목, 하위검사 등) 으로 이루어져 있으면 된다.

- CTT 가정 하에...
  - Cov(Xpi, Xqi) = Cov(Tpi, Tqi) = Cov(Tpi, Tpi+상수) = Var(Tpi)
  - 따라서, 만약 항목이 P개라면,
    신뢰도 = Var(Tyi) / Var(Yi) = (P/(P-1)) * (Var(Yi) - PVar(Xi)) / Var(Yi) = 크론바흐 알파
  - P=1이면 크론바흐 알파값 측정이 불가능함
  - P가 무한에 가까워지면, 크론바흐 알파값은 1에 가까워짐.
    - 검사의 subset이 많을수록 검사의 신뢰도가 높아짐!

- 내적 합치도 (internal consistency) 라고도 부른다.
  - 검사 항목 사이의 상관관계가 강할수록, 값이 높아지기 때문에.

- 모분산은 알 수 없으므로, 표본 분산과 표본 공분산으로 크론바흐 알파 값을 추정해야 함.



### Spearman-Brown Formula

- 함접수 신뢰도에 대한 또다른 공식
- 항목 (또는 하위 검사)들이 병렬일 때, 항목 신뢰도와 합점수 신뢰도 사이의 관계
  - ex) 어떤 검사가 10개의 subsets로 이루어져 있다.
    각 subset들의 reliability coefficient가 모두 0.5로 알려졌다.
    이때, 합점수 신뢰도는 얼마인가?
- 공식
  - 신뢰도 = P * 각신뢰도 / (1 + (P-1)*각신뢰도)
  - ex) 값 = 10 * 0.5 / (1 + 9*0.5) = 5 / 5.5 = 0.909
  - 각신뢰도가 0.5로 낮은 편인데도 합점수 신뢰도는 0.909라는 높은 값이 나온다.
  - P = 1 이면 신뢰도 = 각신뢰도
  - P가 무한에 가까워지면, 신뢰도는 1에 가까워진다.



검사 신뢰도는 일반적인 경우에 0.8을 넘는 것이 좋다고 카더라...
